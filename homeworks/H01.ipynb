{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H.01 | Introduction to SQL and OLAP\n",
    "\n",
    "H.01 will serve as a simple introduction to SQL and OLAP. It will cover the basic concepts and provide a foundation for understanding how to work with databases and perform data analysis using SQL. We'll use Snowflake as our database and TPC-H as our dataset.\n",
    "\n",
    "## Snowflake\n",
    "\n",
    "Snowflake is a cloud-based data warehousing platform that provides a powerful and flexible environment for storing, processing, and analyzing large volumes of data. It is designed to handle complex data workloads and offers features such as scalability, high performance, and ease of use. Snowflake supports SQL as its primary query language, making it accessible to users familiar with SQL. We will be using Snowflake in H.01 to demonstrate the concepts of SQL and OLAP.\n",
    "\n",
    "Please ensure you have the .env file filled out in the root of this folder, it is required to connect to Snowflake. \n",
    "\n",
    "## TPC-H \n",
    "\n",
    "TPC-H is a dataset that simulates a real-world business environment, and has relatively simple schema. It is widely used for testing and comparing the performance of different database systems. We're going to use TPC-H to demonstrate the concepts of SQL and OLAP. The dataset consists of several tables, each representing a different aspect of the business. The tables are related to each other through foreign keys, which allow us to join them together and perform complex queries.\n",
    "\n",
    "<div style=\"align: center; justify-content: center; display: flex;\">\n",
    "    <img src=\"https://docs.snowflake.com/en/_images/sample-data-tpch-schema.png\" alt=\"Snowflake Schema\" width=\"400\" height=\"400\" style = \"border-radius: 10px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowflake Connection\n",
    "\n",
    "To connect to Snowflake, we will use the `snowflake-connector-python` library. This library provides a simple and efficient way to connect to Snowflake and execute SQL queries. We will also use the `pandas` library to load the data into a DataFrame for easy viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.connection import connect_to_snowflake, as_dataframe\n",
    "conn = connect_to_snowflake(database=\"SNOWFLAKE_SAMPLE_DATA\", schema=\"TPCH_SF1\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 | Basic SQL Practice\n",
    "\n",
    "This part of the homework will focus on using the Snowflake Connector for Python to connect to a Snowflake database and perform basic operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1\n",
    "\n",
    "Retrieve the names and account balances of all customers whose balance is greater than 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_NAME</th>\n",
       "      <th>C_ACCTBAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customer#000060001</td>\n",
       "      <td>9957.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer#000060004</td>\n",
       "      <td>7975.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Customer#000060006</td>\n",
       "      <td>9051.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Customer#000060007</td>\n",
       "      <td>6017.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer#000060008</td>\n",
       "      <td>5621.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67984</th>\n",
       "      <td>Customer#000104992</td>\n",
       "      <td>6705.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67985</th>\n",
       "      <td>Customer#000104993</td>\n",
       "      <td>8245.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67986</th>\n",
       "      <td>Customer#000104996</td>\n",
       "      <td>8180.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67987</th>\n",
       "      <td>Customer#000104998</td>\n",
       "      <td>9792.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67988</th>\n",
       "      <td>Customer#000104999</td>\n",
       "      <td>5064.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67989 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   C_NAME C_ACCTBAL\n",
       "0      Customer#000060001   9957.56\n",
       "1      Customer#000060004   7975.22\n",
       "2      Customer#000060006   9051.40\n",
       "3      Customer#000060007   6017.17\n",
       "4      Customer#000060008   5621.44\n",
       "...                   ...       ...\n",
       "67984  Customer#000104992   6705.85\n",
       "67985  Customer#000104993   8245.59\n",
       "67986  Customer#000104996   8180.80\n",
       "67987  Customer#000104998   9792.23\n",
       "67988  Customer#000104999   5064.84\n",
       "\n",
       "[67989 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = \"\"\" \"\"\"\n",
    "cursor.execute(QUERY)\n",
    "rows = cursor.fetchall()\n",
    "as_dataframe(rows, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2\n",
    "\n",
    "List all orders with an order date in January 1995."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O_ORDERKEY</th>\n",
       "      <th>O_ORDERDATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4200263</td>\n",
       "      <td>1995-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4200421</td>\n",
       "      <td>1995-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4200673</td>\n",
       "      <td>1995-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4200930</td>\n",
       "      <td>1995-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4200998</td>\n",
       "      <td>1995-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19467</th>\n",
       "      <td>1196800</td>\n",
       "      <td>1995-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19468</th>\n",
       "      <td>1197057</td>\n",
       "      <td>1995-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19469</th>\n",
       "      <td>1197856</td>\n",
       "      <td>1995-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19470</th>\n",
       "      <td>1198468</td>\n",
       "      <td>1995-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19471</th>\n",
       "      <td>1199302</td>\n",
       "      <td>1995-01-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19472 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       O_ORDERKEY O_ORDERDATE\n",
       "0         4200263  1995-01-20\n",
       "1         4200421  1995-01-01\n",
       "2         4200673  1995-01-05\n",
       "3         4200930  1995-01-06\n",
       "4         4200998  1995-01-14\n",
       "...           ...         ...\n",
       "19467     1196800  1995-01-26\n",
       "19468     1197057  1995-01-29\n",
       "19469     1197856  1995-01-31\n",
       "19470     1198468  1995-01-10\n",
       "19471     1199302  1995-01-23\n",
       "\n",
       "[19472 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = \"\"\" \"\"\"\n",
    "cursor.execute(QUERY)\n",
    "rows = cursor.fetchall()\n",
    "as_dataframe(rows, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.3\n",
    "\n",
    "Find the total number of parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\" \"\"\"\n",
    "cursor.execute(QUERY)\n",
    "rows = cursor.fetchall()\n",
    "as_dataframe(rows, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.4\n",
    "\n",
    "List the top 5 suppliers with the highest account balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\" \"\"\"\n",
    "cursor.execute(QUERY)\n",
    "rows = cursor.fetchall()\n",
    "as_dataframe(rows, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.5\n",
    "\n",
    "Calculate the average order price across all orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\" \"\"\"\n",
    "cursor.execute(QUERY)\n",
    "rows = cursor.fetchall()\n",
    "as_dataframe(rows, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1.6\n",
    "\n",
    "Retrieve the names of parts supplied by suppliers from nation number 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\" \"\"\"\n",
    "cursor.execute(QUERY)\n",
    "rows = cursor.fetchall()\n",
    "as_dataframe(rows, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.7\n",
    "\n",
    "Find the total extended price for each order. Return the order key and total extended price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\" \"\"\"\n",
    "cursor.execute(QUERY)\n",
    "rows = cursor.fetchall()\n",
    "as_dataframe(rows, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.8\n",
    "\n",
    "Retrieve the names of customers who have orders with a total price greater than 100,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\" \"\"\"\n",
    "cursor.execute(QUERY)\n",
    "rows = cursor.fetchall()\n",
    "as_dataframe(rows, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 | Demonstration of Serverless OLAP Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demonstrate the power of Snowflake & Modern OLAP systems. \n",
    "\n",
    "There is a table named `lineitem` in the TPCH_SF1 schema. The table `lineitem` has a column named `l_quantity`, which represents the quantity of items sold in that transaction. The table has **6 million rows**. Let's explore two different approaches to get the average quantity sold.\n",
    "\n",
    "**Note**: A few seconds may not seem like a big deal. If you change \"TPCH_SF1\" to \"TPCH_SF100\" (which has 600 million rows), the difference will be more apparent. This demo will also cost more, so I don't recommend running it unless you're willing to burn a few dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slow Approach\n",
    "\n",
    "The easiest approach to calculating the average quantity is to download the entire table and then calculate the average using pandas. This is a **slow** and **expensive** approach, as it requires downloading all 6 million rows of data. For larger datasets, this approach is not feasible as you will run out of memory in your local setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_QUANTITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.507967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AVG_QUANTITY\n",
       "0     25.507967"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SLOW_QUERY = \"select l_quantity from lineitem;\"\n",
    "df = pd.read_sql(SLOW_QUERY, conn)\n",
    "avg_quantity = float(df[\"L_QUANTITY\"].mean())\n",
    "\n",
    "# Format into a nice table.\n",
    "df = pd.DataFrame({\"AVG_QUANTITY\": [avg_quantity]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Approach\n",
    "\n",
    "The fast approach is to use the Snowflake SQL engine to calculate the average quantity sold. This approach is much faster and more efficient, as it only requires downloading a small amount of data and the computation is done on the (scalable) Snowflake server. This does incur a cost, but ultimately it will be cheaper to operate than a large local server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_QUANTITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.507967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AVG_QUANTITY\n",
       "0     25.507967"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAST_QUERY = \"select AVG(l_quantity) as avg_quantity from lineitem;\"\n",
    "df = pd.read_sql(FAST_QUERY, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit\n",
    "\n",
    "For your convenience, you can just submit your homework by running the cell below. An input box will pop up at the top of the notebook. Respond \"y\" to submit your homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting H.01...\n",
      "{'course_id': 'MBAI', 'datetime': '2025-03-17T10:41:50.487903', 'homework': 'H01.ipynb', 'notebook_code': '{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"# H.01 | Introduction to SQL and OLAP\\\\n\",\\n    \"\\\\n\",\\n    \"H.01 will serve as a simple introduction to SQL and OLAP. It will cover the basic concepts and provide a foundation for understanding how to work with databases and perform data analysis using SQL. We\\'ll use Snowflake as our database and TPC-H as our dataset.\\\\n\",\\n    \"\\\\n\",\\n    \"## Snowflake\\\\n\",\\n    \"\\\\n\",\\n    \"Snowflake is a cloud-based data warehousing platform that provides a powerful and flexible environment for storing, processing, and analyzing large volumes of data. It is designed to handle complex data workloads and offers features such as scalability, high performance, and ease of use. Snowflake supports SQL as its primary query language, making it accessible to users familiar with SQL. We will be using Snowflake in H.01 to demonstrate the concepts of SQL and OLAP.\\\\n\",\\n    \"\\\\n\",\\n    \"Please ensure you have the .env file filled out in the root of this folder, it is required to connect to Snowflake. \\\\n\",\\n    \"\\\\n\",\\n    \"## TPC-H \\\\n\",\\n    \"\\\\n\",\\n    \"TPC-H is a dataset that simulates a real-world business environment, and has relatively simple schema. It is widely used for testing and comparing the performance of different database systems. We\\'re going to use TPC-H to demonstrate the concepts of SQL and OLAP. The dataset consists of several tables, each representing a different aspect of the business. The tables are related to each other through foreign keys, which allow us to join them together and perform complex queries.\\\\n\",\\n    \"\\\\n\",\\n    \"<div style=\\\\\"align: center; justify-content: center; display: flex;\\\\\">\\\\n\",\\n    \"    <img src=\\\\\"https://docs.snowflake.com/en/_images/sample-data-tpch-schema.png\\\\\" alt=\\\\\"Snowflake Schema\\\\\" width=\\\\\"400\\\\\" height=\\\\\"400\\\\\">\\\\n\",\\n    \"</div>\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Snowflake Connection\\\\n\",\\n    \"\\\\n\",\\n    \"To connect to Snowflake, we will use the `snowflake-connector-python` library. This library provides a simple and efficient way to connect to Snowflake and execute SQL queries. We will also use the `pandas` library to load the data into a DataFrame for easy viewing.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 4,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"from connection import connect_to_snowflake, as_dataframe\\\\n\",\\n    \"conn = connect_to_snowflake(database=\\\\\"SNOWFLAKE_SAMPLE_DATA\\\\\", schema=\\\\\"TPCH_SF1\\\\\")\\\\n\",\\n    \"cursor = conn.cursor()\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"# Exercise 1 | Basic SQL Practice\\\\n\",\\n    \"\\\\n\",\\n    \"This part of the homework will focus on using the Snowflake Connector for Python to connect to a Snowflake database and perform basic operations.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Exercise 1.1\\\\n\",\\n    \"\\\\n\",\\n    \"Retrieve the names and account balances of all customers whose balance is greater than 5000.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/html\": [\\n       \"<div>\\\\n\",\\n       \"<style scoped>\\\\n\",\\n       \"    .dataframe tbody tr th:only-of-type {\\\\n\",\\n       \"        vertical-align: middle;\\\\n\",\\n       \"    }\\\\n\",\\n       \"\\\\n\",\\n       \"    .dataframe tbody tr th {\\\\n\",\\n       \"        vertical-align: top;\\\\n\",\\n       \"    }\\\\n\",\\n       \"\\\\n\",\\n       \"    .dataframe thead th {\\\\n\",\\n       \"        text-align: right;\\\\n\",\\n       \"    }\\\\n\",\\n       \"</style>\\\\n\",\\n       \"<table border=\\\\\"1\\\\\" class=\\\\\"dataframe\\\\\">\\\\n\",\\n       \"  <thead>\\\\n\",\\n       \"    <tr style=\\\\\"text-align: right;\\\\\">\\\\n\",\\n       \"      <th></th>\\\\n\",\\n       \"      <th>C_NAME</th>\\\\n\",\\n       \"      <th>C_ACCTBAL</th>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"  </thead>\\\\n\",\\n       \"  <tbody>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>0</th>\\\\n\",\\n       \"      <td>Customer#000060001</td>\\\\n\",\\n       \"      <td>9957.56</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>1</th>\\\\n\",\\n       \"      <td>Customer#000060004</td>\\\\n\",\\n       \"      <td>7975.22</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>2</th>\\\\n\",\\n       \"      <td>Customer#000060006</td>\\\\n\",\\n       \"      <td>9051.40</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>3</th>\\\\n\",\\n       \"      <td>Customer#000060007</td>\\\\n\",\\n       \"      <td>6017.17</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>4</th>\\\\n\",\\n       \"      <td>Customer#000060008</td>\\\\n\",\\n       \"      <td>5621.44</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>...</th>\\\\n\",\\n       \"      <td>...</td>\\\\n\",\\n       \"      <td>...</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>67984</th>\\\\n\",\\n       \"      <td>Customer#000104992</td>\\\\n\",\\n       \"      <td>6705.85</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>67985</th>\\\\n\",\\n       \"      <td>Customer#000104993</td>\\\\n\",\\n       \"      <td>8245.59</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>67986</th>\\\\n\",\\n       \"      <td>Customer#000104996</td>\\\\n\",\\n       \"      <td>8180.80</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>67987</th>\\\\n\",\\n       \"      <td>Customer#000104998</td>\\\\n\",\\n       \"      <td>9792.23</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>67988</th>\\\\n\",\\n       \"      <td>Customer#000104999</td>\\\\n\",\\n       \"      <td>5064.84</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"  </tbody>\\\\n\",\\n       \"</table>\\\\n\",\\n       \"<p>67989 rows × 2 columns</p>\\\\n\",\\n       \"</div>\"\\n      ],\\n      \"text/plain\": [\\n       \"                   C_NAME C_ACCTBAL\\\\n\",\\n       \"0      Customer#000060001   9957.56\\\\n\",\\n       \"1      Customer#000060004   7975.22\\\\n\",\\n       \"2      Customer#000060006   9051.40\\\\n\",\\n       \"3      Customer#000060007   6017.17\\\\n\",\\n       \"4      Customer#000060008   5621.44\\\\n\",\\n       \"...                   ...       ...\\\\n\",\\n       \"67984  Customer#000104992   6705.85\\\\n\",\\n       \"67985  Customer#000104993   8245.59\\\\n\",\\n       \"67986  Customer#000104996   8180.80\\\\n\",\\n       \"67987  Customer#000104998   9792.23\\\\n\",\\n       \"67988  Customer#000104999   5064.84\\\\n\",\\n       \"\\\\n\",\\n       \"[67989 rows x 2 columns]\"\\n      ]\\n     },\\n     \"execution_count\": 5,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"QUERY = \\\\\"\\\\\"\\\\\" \\\\\"\\\\\"\\\\\"\\\\n\",\\n    \"cursor.execute(QUERY)\\\\n\",\\n    \"rows = cursor.fetchall()\\\\n\",\\n    \"as_dataframe(rows, cursor)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Exercise 1.2\\\\n\",\\n    \"\\\\n\",\\n    \"List all orders with an order date in January 1995.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/html\": [\\n       \"<div>\\\\n\",\\n       \"<style scoped>\\\\n\",\\n       \"    .dataframe tbody tr th:only-of-type {\\\\n\",\\n       \"        vertical-align: middle;\\\\n\",\\n       \"    }\\\\n\",\\n       \"\\\\n\",\\n       \"    .dataframe tbody tr th {\\\\n\",\\n       \"        vertical-align: top;\\\\n\",\\n       \"    }\\\\n\",\\n       \"\\\\n\",\\n       \"    .dataframe thead th {\\\\n\",\\n       \"        text-align: right;\\\\n\",\\n       \"    }\\\\n\",\\n       \"</style>\\\\n\",\\n       \"<table border=\\\\\"1\\\\\" class=\\\\\"dataframe\\\\\">\\\\n\",\\n       \"  <thead>\\\\n\",\\n       \"    <tr style=\\\\\"text-align: right;\\\\\">\\\\n\",\\n       \"      <th></th>\\\\n\",\\n       \"      <th>O_ORDERKEY</th>\\\\n\",\\n       \"      <th>O_ORDERDATE</th>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"  </thead>\\\\n\",\\n       \"  <tbody>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>0</th>\\\\n\",\\n       \"      <td>4200263</td>\\\\n\",\\n       \"      <td>1995-01-20</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>1</th>\\\\n\",\\n       \"      <td>4200421</td>\\\\n\",\\n       \"      <td>1995-01-01</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>2</th>\\\\n\",\\n       \"      <td>4200673</td>\\\\n\",\\n       \"      <td>1995-01-05</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>3</th>\\\\n\",\\n       \"      <td>4200930</td>\\\\n\",\\n       \"      <td>1995-01-06</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>4</th>\\\\n\",\\n       \"      <td>4200998</td>\\\\n\",\\n       \"      <td>1995-01-14</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>...</th>\\\\n\",\\n       \"      <td>...</td>\\\\n\",\\n       \"      <td>...</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>19467</th>\\\\n\",\\n       \"      <td>1196800</td>\\\\n\",\\n       \"      <td>1995-01-26</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>19468</th>\\\\n\",\\n       \"      <td>1197057</td>\\\\n\",\\n       \"      <td>1995-01-29</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>19469</th>\\\\n\",\\n       \"      <td>1197856</td>\\\\n\",\\n       \"      <td>1995-01-31</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>19470</th>\\\\n\",\\n       \"      <td>1198468</td>\\\\n\",\\n       \"      <td>1995-01-10</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>19471</th>\\\\n\",\\n       \"      <td>1199302</td>\\\\n\",\\n       \"      <td>1995-01-23</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"  </tbody>\\\\n\",\\n       \"</table>\\\\n\",\\n       \"<p>19472 rows × 2 columns</p>\\\\n\",\\n       \"</div>\"\\n      ],\\n      \"text/plain\": [\\n       \"       O_ORDERKEY O_ORDERDATE\\\\n\",\\n       \"0         4200263  1995-01-20\\\\n\",\\n       \"1         4200421  1995-01-01\\\\n\",\\n       \"2         4200673  1995-01-05\\\\n\",\\n       \"3         4200930  1995-01-06\\\\n\",\\n       \"4         4200998  1995-01-14\\\\n\",\\n       \"...           ...         ...\\\\n\",\\n       \"19467     1196800  1995-01-26\\\\n\",\\n       \"19468     1197057  1995-01-29\\\\n\",\\n       \"19469     1197856  1995-01-31\\\\n\",\\n       \"19470     1198468  1995-01-10\\\\n\",\\n       \"19471     1199302  1995-01-23\\\\n\",\\n       \"\\\\n\",\\n       \"[19472 rows x 2 columns]\"\\n      ]\\n     },\\n     \"execution_count\": 6,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"QUERY = \\\\\"\\\\\"\\\\\" \\\\\"\\\\\"\\\\\"\\\\n\",\\n    \"cursor.execute(QUERY)\\\\n\",\\n    \"rows = cursor.fetchall()\\\\n\",\\n    \"as_dataframe(rows, cursor)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Exercise 1.3\\\\n\",\\n    \"\\\\n\",\\n    \"Find the total number of parts.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"QUERY = \\\\\"\\\\\"\\\\\" \\\\\"\\\\\"\\\\\"\\\\n\",\\n    \"cursor.execute(QUERY)\\\\n\",\\n    \"rows = cursor.fetchall()\\\\n\",\\n    \"as_dataframe(rows, cursor)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Exercise 1.4\\\\n\",\\n    \"\\\\n\",\\n    \"List the top 5 suppliers with the highest account balance.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"QUERY = \\\\\"\\\\\"\\\\\" \\\\\"\\\\\"\\\\\"\\\\n\",\\n    \"cursor.execute(QUERY)\\\\n\",\\n    \"rows = cursor.fetchall()\\\\n\",\\n    \"as_dataframe(rows, cursor)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Exercise 1.5\\\\n\",\\n    \"\\\\n\",\\n    \"Calculate the average order price across all orders.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"QUERY = \\\\\"\\\\\"\\\\\" \\\\\"\\\\\"\\\\\"\\\\n\",\\n    \"cursor.execute(QUERY)\\\\n\",\\n    \"rows = cursor.fetchall()\\\\n\",\\n    \"as_dataframe(rows, cursor)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Excercise 1.6\\\\n\",\\n    \"\\\\n\",\\n    \"Retrieve the names of parts supplied by suppliers from nation number 3.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"QUERY = \\\\\"\\\\\"\\\\\" \\\\\"\\\\\"\\\\\"\\\\n\",\\n    \"cursor.execute(QUERY)\\\\n\",\\n    \"rows = cursor.fetchall()\\\\n\",\\n    \"as_dataframe(rows, cursor)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Exercise 1.7\\\\n\",\\n    \"\\\\n\",\\n    \"Find the total extended price for each order. Return the order key and total extended price.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"QUERY = \\\\\"\\\\\"\\\\\" \\\\\"\\\\\"\\\\\"\\\\n\",\\n    \"cursor.execute(QUERY)\\\\n\",\\n    \"rows = cursor.fetchall()\\\\n\",\\n    \"as_dataframe(rows, cursor)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Exercise 1.8\\\\n\",\\n    \"\\\\n\",\\n    \"Retrieve the names of customers who have orders with a total price greater than 100,000.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"QUERY = \\\\\"\\\\\"\\\\\" \\\\\"\\\\\"\\\\\"\\\\n\",\\n    \"cursor.execute(QUERY)\\\\n\",\\n    \"rows = cursor.fetchall()\\\\n\",\\n    \"as_dataframe(rows, cursor)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"# Exercise 2 | Demonstration of Serverless OLAP Speed\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Let\\'s demonstrate the power of Snowflake & Modern OLAP systems. \\\\n\",\\n    \"\\\\n\",\\n    \"There is a table named `lineitem` in the TPCH_SF1 schema. The table `lineitem` has a column named `l_quantity`, which represents the quantity of items sold in that transaction. The table has **6 million rows**. Let\\'s explore two different approaches to get the average quantity sold.\\\\n\",\\n    \"\\\\n\",\\n    \"**Note**: A few seconds may not seem like a big deal. If you change \\\\\"TPCH_SF1\\\\\" to \\\\\"TPCH_SF100\\\\\" (which has 600 million rows), the difference will be more apparent. This demo will also cost more, so I don\\'t recommend running it unless you\\'re willing to burn a few dollars.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"### Slow Approach\\\\n\",\\n    \"\\\\n\",\\n    \"The easiest approach to calculating the average quantity is to download the entire table and then calculate the average using pandas. This is a **slow** and **expensive** approach, as it requires downloading all 6 million rows of data. For larger datasets, this approach is not feasible as you will run out of memory in your local setup.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 7,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/html\": [\\n       \"<div>\\\\n\",\\n       \"<style scoped>\\\\n\",\\n       \"    .dataframe tbody tr th:only-of-type {\\\\n\",\\n       \"        vertical-align: middle;\\\\n\",\\n       \"    }\\\\n\",\\n       \"\\\\n\",\\n       \"    .dataframe tbody tr th {\\\\n\",\\n       \"        vertical-align: top;\\\\n\",\\n       \"    }\\\\n\",\\n       \"\\\\n\",\\n       \"    .dataframe thead th {\\\\n\",\\n       \"        text-align: right;\\\\n\",\\n       \"    }\\\\n\",\\n       \"</style>\\\\n\",\\n       \"<table border=\\\\\"1\\\\\" class=\\\\\"dataframe\\\\\">\\\\n\",\\n       \"  <thead>\\\\n\",\\n       \"    <tr style=\\\\\"text-align: right;\\\\\">\\\\n\",\\n       \"      <th></th>\\\\n\",\\n       \"      <th>AVG_QUANTITY</th>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"  </thead>\\\\n\",\\n       \"  <tbody>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>0</th>\\\\n\",\\n       \"      <td>25.507967</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"  </tbody>\\\\n\",\\n       \"</table>\\\\n\",\\n       \"</div>\"\\n      ],\\n      \"text/plain\": [\\n       \"   AVG_QUANTITY\\\\n\",\\n       \"0     25.507967\"\\n      ]\\n     },\\n     \"execution_count\": 7,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"import pandas as pd\\\\n\",\\n    \"\\\\n\",\\n    \"SLOW_QUERY = \\\\\"select l_quantity from lineitem;\\\\\"\\\\n\",\\n    \"df = pd.read_sql(SLOW_QUERY, conn)\\\\n\",\\n    \"avg_quantity = float(df[\\\\\"L_QUANTITY\\\\\"].mean())\\\\n\",\\n    \"\\\\n\",\\n    \"# Format into a nice table.\\\\n\",\\n    \"df = pd.DataFrame({\\\\\"AVG_QUANTITY\\\\\": [avg_quantity]})\\\\n\",\\n    \"df\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"### Fast Approach\\\\n\",\\n    \"\\\\n\",\\n    \"The fast approach is to use the Snowflake SQL engine to calculate the average quantity sold. This approach is much faster and more efficient, as it only requires downloading a small amount of data and the computation is done on the (scalable) Snowflake server. This does incur a cost, but ultimately it will be cheaper to operate than a large local server.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 8,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/html\": [\\n       \"<div>\\\\n\",\\n       \"<style scoped>\\\\n\",\\n       \"    .dataframe tbody tr th:only-of-type {\\\\n\",\\n       \"        vertical-align: middle;\\\\n\",\\n       \"    }\\\\n\",\\n       \"\\\\n\",\\n       \"    .dataframe tbody tr th {\\\\n\",\\n       \"        vertical-align: top;\\\\n\",\\n       \"    }\\\\n\",\\n       \"\\\\n\",\\n       \"    .dataframe thead th {\\\\n\",\\n       \"        text-align: right;\\\\n\",\\n       \"    }\\\\n\",\\n       \"</style>\\\\n\",\\n       \"<table border=\\\\\"1\\\\\" class=\\\\\"dataframe\\\\\">\\\\n\",\\n       \"  <thead>\\\\n\",\\n       \"    <tr style=\\\\\"text-align: right;\\\\\">\\\\n\",\\n       \"      <th></th>\\\\n\",\\n       \"      <th>AVG_QUANTITY</th>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"  </thead>\\\\n\",\\n       \"  <tbody>\\\\n\",\\n       \"    <tr>\\\\n\",\\n       \"      <th>0</th>\\\\n\",\\n       \"      <td>25.507967</td>\\\\n\",\\n       \"    </tr>\\\\n\",\\n       \"  </tbody>\\\\n\",\\n       \"</table>\\\\n\",\\n       \"</div>\"\\n      ],\\n      \"text/plain\": [\\n       \"   AVG_QUANTITY\\\\n\",\\n       \"0     25.507967\"\\n      ]\\n     },\\n     \"execution_count\": 8,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"FAST_QUERY = \\\\\"select AVG(l_quantity) as avg_quantity from lineitem;\\\\\"\\\\n\",\\n    \"df = pd.read_sql(FAST_QUERY, conn)\\\\n\",\\n    \"df\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"# Submit\\\\n\",\\n    \"\\\\n\",\\n    \"For your convenience, you can just submit your homework by running the cell below. An input box will pop up at the top of the notebook. Respond \\\\\"y\\\\\" to submit your homework.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 2,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"Submitting H.01...\\\\n\",\\n      \"{\\'course_id\\': \\'MBAI\\', \\'datetime\\': \\'2025-03-17T10:35:09.634934\\', \\'homework\\': \\'machine_learning.py\\', \\'notebook_code\\': \\'from typing import Tuple\\\\\\\\nimport numpy as np\\\\\\\\nfrom typing import Callable\\\\\\\\nfrom sklearn.model_selection import train_test_split\\\\\\\\n\\\\\\\\ndef binarize(labels: list[str]) -> np.array:\\\\\\\\n    \\\\\"\\\\\"\\\\\"Binarize the labels.\\\\\\\\n\\\\\\\\n    Binarize the labels such that \\\\\"Chinstrap\\\\\" is 1 and \\\\\"Adelie\\\\\" is 0.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        labels (list[str]): The labels to binarize.\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        np.array: The binarized labels.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    return np.array([1 if label == \\\\\"Chinstrap\\\\\" else 0 for label in labels])\\\\\\\\n\\\\\\\\ndef split_data(X: np.array, y: np.array, test_size: float=0.2, \\\\\\\\n                random_state: float = 42, shuffle: bool = True) -> Tuple[np.array, np.array, np.array, np.array]:\\\\\\\\n    \\\\\"\\\\\"\\\\\"Split the data into training and testing sets.\\\\\\\\n\\\\\\\\n    NOTE:\\\\\\\\n        Please use the train_test_split function from sklearn to split the data.\\\\\\\\n        Ensure your test_size is set to 0.2.\\\\\\\\n        Ensure your random_state is set to 42.\\\\\\\\n        Ensure shuffle is set to True.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        X (np.array): The independent variables.\\\\\\\\n        y (np.array): The dependent variables.\\\\\\\\n        test_size (float): The proportion of the data to use for testing.\\\\\\\\n        random_state (int): The random seed to use for the split.\\\\\\\\n        shuffle (bool): Whether or not to shuffle the data before splitting.\\\\\\\\n\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n\\\\\\\\n    raise NotImplementedError(\\\\\"Please implement the split_data function.\\\\\")\\\\\\\\n\\\\\\\\ndef standardize(X_train: np.array, X_test: np.array) -> Tuple[np.array, np.array]:\\\\\\\\n    \\\\\"\\\\\"\\\\\"Standardize the training and testing data.\\\\\\\\n\\\\\\\\n    Standardize the training and testing data using the mean and standard deviation of\\\\\\\\n    the training set.\\\\\\\\n\\\\\\\\n    Recall that your samples are rows and your features are columns. Your goal is to\\\\\\\\n    standardize along the columns (features).\\\\\\\\n    \\\\\\\\n    NOTE: Ensure you use the mean and standard deviation of the training set for\\\\\\\\n    standardization of BOTH training and testing sets. This will accomplish what\\\\\\\\n    we talked about in lecture, where it is imperative to standardize them \\\\\\\\n    separately. You should NOT use data from the testing set to standardize the\\\\\\\\n    training set, because it would be leaking information from the testing set.\\\\\\\\n    You should NOT use data from the testing set to standardize the testing set,\\\\\\\\n    because it would be like looking into the future and impairs the generalization\\\\\\\\n    of the model.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        X_train (np.array): The training data.\\\\\\\\n        X_test (np.array): The testing data.\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Tuple[np.array, np.array]: The standardized training and testing data.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    raise NotImplementedError(\\\\\"Please implement the standardize function.\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\ndef euclidean_distance(x1: np.array, x2: np.array) -> float:\\\\\\\\n    \\\\\"\\\\\"\\\\\"Calculate the Euclidean distance between two points x1 and x2.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        x1 (np.array): The first point.\\\\\\\\n        x2 (np.array): The second point.\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        float: The Euclidean distance between the two points.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    raise NotImplementedError(\\\\\"Please implement the euclidean_distance function.\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\ndef cosine_distance(x1: np.array, x2: np.array) -> float:\\\\\\\\n    \\\\\"\\\\\"\\\\\"Calculate the cosine distance between two points x1 and x2.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        x1 (np.array): The first point.\\\\\\\\n        x2 (np.array): The second point.\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        float: The cosine distance between the two points.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    raise NotImplementedError(\\\\\"Please implement the cosine_distance function.\\\\\")\\\\\\\\n    \\\\\\\\ndef knn(x: np.array, y: np.array, \\\\\\\\n        sample: np.array, distance_method: Callable, k: int) -> int:\\\\\\\\n    \\\\\"\\\\\"\\\\\"Perform k-nearest neighbors classification.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        X (np.array): The training data.\\\\\\\\n        y (np.array): The training labels.\\\\\\\\n        sample (np.array): The point you want to classify.\\\\\\\\n        distance_method (Callable): The distance metric to use. This MUST \\\\\\\\n            accept two np.arrays and return a float.\\\\\\\\n        k (int): The number of neighbors to consider as equal votes.\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        int: The label of the sample.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n\\\\\\\\n    # (distance, label) between the test sample and all the training samples.\\\\\\\\n    distances = []\\\\\\\\n\\\\\\\\n    for x_i, y_i in zip(x, y):\\\\\\\\n\\\\\\\\n        # 1. Calculate the distance between the test sample and the training sample.\\\\\\\\n        \\\\\\\\n        # 2. Append the (distance, label) tuple to the distances list.\\\\\\\\n\\\\\\\\n        raise NotImplementedError(\\\\\"Please implement the knn function distance loop.\\\\\")\\\\\\\\n\\\\\\\\n    # 3. Sort the tuples by distance (the first element of each tuple in distances).\\\\\\\\n\\\\\\\\n    # 4. Get the unique labels and their counts. HINT: np.unique has a return_counts parameter.\\\\\\\\n\\\\\\\\n    # 5. Return the label with the most counts.\\\\\\\\n    \\\\\\\\n\\\\\\\\ndef linear_regression(X: np.array, y: np.array) -> np.array:\\\\\\\\n    \\\\\"\\\\\"\\\\\"Perform linear regression using the normal equation.\\\\\\\\n\\\\\\\\n    NOTE: It is important that you concatenate a column of ones to the independent\\\\\\\\n    variables X. This will effectively add a bias term to the model.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        X (np.array): The independent variables.\\\\\\\\n        y (np.array): The dependent variables.\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        np.array: The weights for the linear regression model\\\\\\\\n                (including the bias term)\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n\\\\\\\\n    # 1. Concatenate the bias term to X using np.hstack.\\\\\\\\n\\\\\\\\n    # 2. Calculate the weights using the normal equation.\\\\\\\\n\\\\\\\\n    raise NotImplementedError(\\\\\"Please implement the linear_regression function.\\\\\")\\\\\\\\n\\\\\\\\ndef linear_regression_predict(X: np.array, weights: np.array) -> np.array:\\\\\\\\n    \\\\\"\\\\\"\\\\\"Predict the dependent variables using the weights and independent variables.\\\\\\\\n\\\\\\\\n    NOTE: It is important that you concatenate a column of ones to the independent\\\\\\\\n    variables X. This will effectively add a bias term to the model.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        X (np.array): The independent variables.\\\\\\\\n        weights (np.array): The weights of the linear regression model.\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        np.array: The predicted dependent variables.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    # 1. Concatenate the bias term to X using np.hstack.\\\\\\\\n    \\\\\\\\n    # 2. Calculate the predictions.\\\\\\\\n    \\\\\\\\n    raise NotImplementedError(\\\\\"Please implement the linear_regression_predict function.\\\\\")\\\\\\\\n    \\\\\\\\n\\\\\\\\ndef mean_squared_error(y_true: np.array, y_pred: np.array) -> float:\\\\\\\\n    \\\\\"\\\\\"\\\\\"Calculate the mean squared error.\\\\\\\\n\\\\\\\\n    You should use only numpy for this calculation.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        y_true (np.array): The true values.\\\\\\\\n        y_pred (np.array): The predicted values.\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        float: The mean squared error.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    raise NotImplementedError(\\\\\"Please implement the mean_squared_error function.\\\\\")\\\\\\\\n\\\\\\\\ndef sigmoid(z: np.array) -> np.array:\\\\\\\\n    \\\\\"\\\\\"\\\\\"Calculate the sigmoid function.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        z (np.array): The input to the sigmoid function.\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        np.array: The output of the sigmoid function.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    raise NotImplementedError(\\\\\"Please implement the sigmoid function.\\\\\")\\\\\\\\n\\\\\\\\ndef logistic_regression_gradient_descent(X: np.array, y: np.array, \\\\\\\\n                                         learning_rate: float = 0.01, \\\\\\\\n                                         num_iterations: int = 5000) -> np.array:\\\\\\\\n    \\\\\\\\n    \\\\\"\\\\\"\\\\\"Perform logistic regression using gradient descent.\\\\\\\\n\\\\\\\\n    NOTE: It is important that you concatenate a column of ones to the independent\\\\\\\\n    variables before performing gradient descent. This will effectively add\\\\\\\\n    a bias term to the model. The hstack function from numpy will be useful.\\\\\\\\n\\\\\\\\n    NOTE: The weights should be initialized to zeros. np.zeros will be useful.\\\\\\\\n\\\\\\\\n    NOTE: Please follow the formula provided in lecture to update the weights.\\\\\\\\n    Other algorithms will work, but the tests are expecting the weights to be\\\\\\\\n    calculated in the way described in our lecture.\\\\\\\\n\\\\\\\\n    NOTE: The tests expect a learning rate of 0.01 and 5000 iterations. Do\\\\\\\\n    not change these values prior to submission.\\\\\\\\n\\\\\\\\n    NOTE: This function expects you to use the sigmoid function you implemented\\\\\\\\n    above.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        X (np.array): The independent variables.\\\\\\\\n        y (np.array): The dependent variables.\\\\\\\\n        learning_rate (float): The learning rate.\\\\\\\\n        num_iterations (int): The number of iterations to perform.\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        np.array: The weights for the logistic regression model.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    # 1. Concatenate the bias term to X using np.hstack.\\\\\\\\n\\\\\\\\n    # 2. Initialize the weights with zeros. np.zeros is your friend here! \\\\\\\\n    weights = np.zeros(X.shape[1])\\\\\\\\n\\\\\\\\n    # For each iteration, update the weights.\\\\\\\\n    for _ in range(num_iterations):\\\\\\\\n\\\\\\\\n        # 3. Calculate the predictions.\\\\\\\\n\\\\\\\\n        # 4. Calculate the gradient.\\\\\\\\n    \\\\\\\\n        # 5. Update the weights -- make sure to use the learning rate!\\\\\\\\n\\\\\\\\n        raise NotImplementedError(\\\\\"Please implement the logistic_regression_gradient_descent function.\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\ndef logistic_regression_predict(X: np.array, weights: np.array) -> np.array:\\\\\\\\n    \\\\\"\\\\\"\\\\\"Predict the labels for the logistic regression model.\\\\\\\\n\\\\\\\\n    NOTE: This function expects you to use the sigmoid function you implemented\\\\\\\\n    above.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        X (np.array): The independent variables.\\\\\\\\n        weights (np.array): The weights of the logistic regression model. This\\\\\\\\n            should include the bias term.\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        np.array: The output of logistic regression.\\\\\\\\n    \\\\\"\\\\\"\\\\\"\\\\\\\\n    # 1. Add the bias term using np.hstack.\\\\\\\\n\\\\\\\\n    # 2. Calculate the predictions using the provided weights.\\\\\\\\n\\\\\\\\n    raise NotImplementedError(\\\\\"Please implement the logistic_regression_predict function.\\\\\")\\', \\'response\\': \\'sent!\\', \\'username\\': \\'joshuadrc@gmail.com\\'}\\\\n\",\\n      \"H.01 submitted successfully.\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"response = input(\\\\\"Are you sure you want to submit H.01? (y/n): \\\\\")\\\\n\",\\n    \"if response.lower() != \\\\\"y\\\\\":\\\\n\",\\n    \"    print(\\\\\"Submission cancelled.\\\\\")\\\\n\",\\n    \"else:\\\\n\",\\n    \"    print(\\\\\"Submitting H.01...\\\\\")\\\\n\",\\n    \"    !python submit.py --homework ./machine_learning.py\\\\n\",\\n    \"    print(\\\\\"H.01 submitted successfully.\\\\\")\"\\n   ]\\n  }\\n ],\\n \"metadata\": {\\n  \"kernelspec\": {\\n   \"display_name\": \"mbai\",\\n   \"language\": \"python\",\\n   \"name\": \"python3\"\\n  },\\n  \"language_info\": {\\n   \"codemirror_mode\": {\\n    \"name\": \"ipython\",\\n    \"version\": 3\\n   },\\n   \"file_extension\": \".py\",\\n   \"mimetype\": \"text/x-python\",\\n   \"name\": \"python\",\\n   \"nbconvert_exporter\": \"python\",\\n   \"pygments_lexer\": \"ipython3\",\\n   \"version\": \"3.10.16\"\\n  }\\n },\\n \"nbformat\": 4,\\n \"nbformat_minor\": 2\\n}\\n', 'response': 'sent!', 'username': 'joshuadrc@gmail.com'}\n",
      "H.01 submitted successfully.\n"
     ]
    }
   ],
   "source": [
    "response = input(\"Are you sure you want to submit H.01? (y/n): \")\n",
    "if response.lower() != \"y\":\n",
    "    print(\"Submission cancelled.\")\n",
    "else:\n",
    "    print(\"Submitting H.01...\")\n",
    "    !python scripts/submit.py --homework ./H01.ipynb\n",
    "    print(\"H.01 submitted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
